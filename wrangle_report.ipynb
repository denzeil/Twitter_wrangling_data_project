{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc6111f0",
   "metadata": {},
   "source": [
    "## Wrangling report for WeRateDogs Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b191ec87",
   "metadata": {},
   "source": [
    "- Wrangling this project was kind of more tricky and time-consuming than I expected but I have learned a lot. The first part of the data wrangling process is gathering. First, I imported the necessary libraries for my assessment, which are pandas, requests and matplotlib. After that, I programmatically downloaded the image predictions file and saved it. I created a Twitter developer account and accessed the API keys which I stored in variables. I imported the tweepy API and json library. I programmatically downloaded the data using the tweepy API which I saved to a json file and converted to a dataframe.\n",
    " \n",
    "- After gathering, I had 3 datasets to assess for quality and tidiness issues. I read the dataframes and visually the data. Some of the Quality issues I noted in the enhanced_archive table, the Timestamp column was in object format, and columns like retweeted_status_id - retweeted_status_timestamp had missing values. In the data_convert table, there were two columns for idâ€™s, the columns geo to contributors have almost no values, and the column display_text_range is in object form and has a value range from 0. I also did a programmatic assessment by checking the number of columns in each dataset and using the value counts function to check the number of recurring values. According to the project rubric, we only need the original tweets for analysis. Some of the tidiness issues I noticed are the four-dog stage columns were separated instead of being one and merging the three datasets\n",
    "- The third part is cleaning. I used a define, code and test approach for each issue I encountered in the assessing part. Some of the issues I dealt with is converting columns in the wrong format like the Timestamp column to date format and dropping columns that had almost no values like retweeted_status_id to in_reply_to_screen_name. I changed the rating denominator to 10 and fixed the tidiness issues by merging the 4 dog breed columns into one and merging all the 3 datasets into one. After cleaning and I saved the new merged dataset to a new csv file called twitter_archive_master.csv. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788777f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
